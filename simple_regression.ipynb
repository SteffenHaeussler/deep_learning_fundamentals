{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Callable, Dict, Tuple, List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "data = boston.data\n",
    "target = boston.target\n",
    "features = boston.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = StandardScaler()\n",
    "data = s.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=80718)\n",
    "\n",
    "y_train, y_test = y_train.reshape(-1, 1), y_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='tanh'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "# Compile model\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = ModelCheckpoint(\"model.h5\", monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# early_stop = EarlyStopping(monitor='val_loss',\n",
    "#                               min_delta=0,\n",
    "#                               patience=2,\n",
    "#                               verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 196\n",
      "Trainable params: 196\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 346.3387 - mse: 346.3387\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 47.9897 - mse: 47.9897\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 34.7853 - mse: 34.7853\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30.4354 - mse: 30.4354\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 26.1046 - mse: 26.1046\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 23.4968 - mse: 23.4968\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 20.6812 - mse: 20.6812\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 18.3333 - mse: 18.3333\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15.9752 - mse: 15.9752\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 19.0503 - mse: 19.0503\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14.7993 - mse: 14.7993\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 14.6512 - mse: 14.6512\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 14.2012 - mse: 14.2012\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12.6787 - mse: 12.6787\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13.5998 - mse: 13.5998\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12.1833 - mse: 12.1833\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 11.9278 - mse: 11.9278\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 11.3577 - mse: 11.3577\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 10.7390 - mse: 10.7390\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 10.9523 - mse: 10.9523\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 10.7910 - mse: 10.7910\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 10.5686 - mse: 10.5686\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 10.0749 - mse: 10.0749\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 10.1288 - mse: 10.1288\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 9.7502 - mse: 9.7502\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 9.2200 - mse: 9.2200\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 9.4411 - mse: 9.4411\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 8.9343 - mse: 8.9343\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 9.1510 - mse: 9.1510\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 8.9547 - mse: 8.9547\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 8.9265 - mse: 8.9265\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 9.3340 - mse: 9.3340\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 8.9433 - mse: 8.9433\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 9.0333 - mse: 9.0333\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 8.5511 - mse: 8.5511\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.8393 - mse: 7.8393\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 8.4334 - mse: 8.4334\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 8.1919 - mse: 8.1919\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 8.1626 - mse: 8.1626\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 7.6483 - mse: 7.6483\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.7981 - mse: 7.7981\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6237 - mse: 7.6237\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 7.8982 - mse: 7.8982\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 8.5071 - mse: 8.5071\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.4038 - mse: 7.4038\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 7.0405 - mse: 7.0405\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 7.3928 - mse: 7.3928\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.2313 - mse: 7.2313\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.2865 - mse: 7.2865\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.8812 - mse: 7.8812\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.8230 - mse: 6.8230\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.3774 - mse: 7.3774\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.7748 - mse: 6.7748\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.6503 - mse: 6.6503\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.0017 - mse: 7.0017\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.5642 - mse: 6.5642\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.0381 - mse: 7.0381\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.8101 - mse: 6.8101\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.9139 - mse: 6.9139\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.7425 - mse: 6.7425\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3569 - mse: 6.3569\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.4007 - mse: 6.4007\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.8201 - mse: 6.8201\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.7058 - mse: 6.7058\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.1239 - mse: 6.1239\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.4858 - mse: 6.4858\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.1858 - mse: 6.1858\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 5.9185 - mse: 5.9185\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.7033 - mse: 6.7033\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.2478 - mse: 6.2478\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.1074 - mse: 6.1074\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.1983 - mse: 6.1983\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 5.9450 - mse: 5.9450\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.6074 - mse: 6.6074\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 5.8944 - mse: 5.8944\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.9087 - mse: 5.9087\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 5.9176 - mse: 5.9176\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 5.8085 - mse: 5.8085\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.0787 - mse: 6.0787\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 5.8765 - mse: 5.8765\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 5.8643 - mse: 5.8643\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 5.5639 - mse: 5.5639\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.7403 - mse: 5.7403\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 5.9083 - mse: 5.9083\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 5.7746 - mse: 5.7746\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 1ms/step - loss: 5.3954 - mse: 5.3954\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.9502 - mse: 5.9502\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.6581 - mse: 5.6581\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 5.5753 - mse: 5.5753\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 5.4797 - mse: 5.4797\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.1258 - mse: 6.1258\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.7393 - mse: 5.7393\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.4816 - mse: 5.4816\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 5.6975 - mse: 5.6975\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 5.3912 - mse: 5.3912\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.3406 - mse: 5.3406\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.4060 - mse: 5.4060\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 5.4943 - mse: 5.4943\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.2692 - mse: 5.2692\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 5.3357 - mse: 5.3357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fedacdf76a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, batch_size=23, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(X_test)\n",
    "test_actual = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.150872037106064"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(test_pred, test_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fedad467640>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(test_pred, test_actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Optimizer\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyTorchTrainer(object):\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 optim: Optimizer,\n",
    "                 criterion: _Loss):\n",
    "        self.model = model\n",
    "        self.optim = optim\n",
    "        self.loss = criterion\n",
    "        self._check_optim_net_aligned()\n",
    "\n",
    "    def _check_optim_net_aligned(self):\n",
    "        assert self.optim.param_groups[0]['params']\\\n",
    "            == list(self.model.parameters())\n",
    "\n",
    "    def _generate_batches(self,\n",
    "                          X: Tensor,\n",
    "                          y: Tensor,\n",
    "                          size: int = 32) -> Tuple[Tensor]:\n",
    "\n",
    "        N = X.shape[0]\n",
    "\n",
    "        for ii in range(0, N, size):\n",
    "            X_batch, y_batch = X[ii:ii+size], y[ii:ii+size]\n",
    "\n",
    "            yield X_batch, y_batch\n",
    "\n",
    "    def _permute_data(self, X: Tensor, y: Tensor, seed=1) -> Tuple[Tensor]:\n",
    "        perm = torch.randperm(X.shape[0])\n",
    "        return X[perm], y[perm]\n",
    "\n",
    "    def fit(self, X_train: Tensor = None,\n",
    "            y_train: Tensor = None,\n",
    "            X_test: Tensor = None,\n",
    "            y_test: Tensor = None,\n",
    "            train_dataloader: DataLoader = None,\n",
    "            test_dataloader: DataLoader = None,\n",
    "            epochs: int=100,\n",
    "            eval_every: int=10,\n",
    "            batch_size: int=32,\n",
    "            final_lr_exp: int = None):\n",
    "\n",
    "        init_lr = self.optim.param_groups[0]['lr']\n",
    "        if final_lr_exp:\n",
    "            decay = (final_lr_exp / init_lr) ** (1.0 / (epochs + 1))\n",
    "            scheduler = lr_scheduler.ExponentialLR(self.optim, gamma=decay)\n",
    "        for e in range(epochs):\n",
    "\n",
    "            if final_lr_exp:\n",
    "                scheduler.step()\n",
    "\n",
    "            if not train_dataloader:\n",
    "                X_train, y_train = self._permute_data(X_train, y_train)\n",
    "\n",
    "                batch_generator = self._generate_batches(X_train, y_train,\n",
    "                                                         batch_size)\n",
    "\n",
    "                self.model.train()\n",
    "\n",
    "                for ii, (X_batch, y_batch) in enumerate(batch_generator):\n",
    "\n",
    "                    self.optim.zero_grad()   # zero the gradient buffers\n",
    "\n",
    "                    output = self.model(X_batch)[0]\n",
    "\n",
    "                    loss = self.loss(output, y_batch)\n",
    "                    loss.backward()\n",
    "                    self.optim.step()\n",
    "\n",
    "                if e % eval_every == 0:\n",
    "                    with torch.no_grad():\n",
    "                        self.model.eval()\n",
    "                        output = self.model(X_test)[0]\n",
    "                        loss = self.loss(output, y_test)\n",
    "                        print(\"The loss after\", e+1, \"epochs was\", loss.item())\n",
    "\n",
    "            else:\n",
    "                for X_batch, y_batch in train_dataloader:\n",
    "\n",
    "                    self.optim.zero_grad()\n",
    "\n",
    "                    output = self.model(X_batch)[0]\n",
    "\n",
    "                    loss = self.loss(output, y_batch)\n",
    "                    loss.backward()\n",
    "                    self.optim.step()\n",
    "\n",
    "                if e % eval_every == 0:\n",
    "                    with torch.no_grad():\n",
    "                        self.model.eval()\n",
    "                        losses = []\n",
    "                        for X_batch, y_batch in test_dataloader:\n",
    "                            output = self.model(X_batch)[0]\n",
    "                            loss = self.loss(output, y_batch)\n",
    "                            losses.append(loss.item())\n",
    "                        print(\"The loss after\", e, \"epochs was\",\n",
    "                              round(torch.Tensor(losses).mean().item(), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyTorchLayer(nn.Module):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x: Tensor,\n",
    "                inference: bool = False) -> Tensor:\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        \n",
    "class PyTorchModel(nn.Module):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tuple[Tensor]:\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        \n",
    "def assert_dim(t: Tensor,\n",
    "               dim: Tensor):\n",
    "    assert len(t.shape) == dim, \\\n",
    "        '''\n",
    "        Tensor expected to have dimension {0}, instead has dimension {1}\n",
    "        '''.format(dim, len(t.shape))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_mode(m: nn.Module):\n",
    "    m.eval()\n",
    "        \n",
    "        \n",
    "class DenseLayer(PyTorchLayer):\n",
    "    def __init__(self,\n",
    "                 input_size: int,\n",
    "                 neurons: int,\n",
    "                 dropout: float = 1.0,\n",
    "                 activation: nn.Module = None) -> None:\n",
    "\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, neurons)\n",
    "        self.activation = activation\n",
    "        if dropout < 1.0:\n",
    "            self.dropout = nn.Dropout(1 - dropout)\n",
    "\n",
    "    def forward(self, x: Tensor,\n",
    "                inference: bool = False) -> Tensor:\n",
    "        if inference:\n",
    "            self.apply(inference_mode)\n",
    "\n",
    "        x = self.linear(x)  # does weight multiplication + bias\n",
    "        if self.activation:\n",
    "            x = self.activation(x)\n",
    "        if hasattr(self, \"dropout\"):\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BostonModel(PyTorchModel):\n",
    "\n",
    "    def __init__(self,\n",
    "                 hidden_size: int = 13,\n",
    "                 hidden_dropout: float = 1.0):\n",
    "        super().__init__()\n",
    "        self.dense1 = DenseLayer(13, hidden_size, \n",
    "                                 activation=nn.Tanh(),\n",
    "                                 dropout = hidden_dropout)\n",
    "        self.dense2 = DenseLayer(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x: Tensor,\n",
    "                inference: bool = False) -> Tensor:\n",
    "        \n",
    "        assert_dim(x, 2)\n",
    "        \n",
    "        assert x.shape[1] == 13\n",
    "\n",
    "        x = self.dense1(x, inference)\n",
    "        return self.dense2(x, inference),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = Tensor(X_train), Tensor(X_test), Tensor(y_train), Tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_boston_model = BostonModel(hidden_size=13, hidden_dropout=0.8)\n",
    "optimizer = torch.optim.SGD(pytorch_boston_model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/steffen/miniconda3/envs/deep_learning/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:118: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss after 1 epochs was 405.6063537597656\n",
      "The loss after 11 epochs was 27.64900016784668\n",
      "The loss after 21 epochs was 20.719297409057617\n",
      "The loss after 31 epochs was 23.351734161376953\n",
      "The loss after 41 epochs was 20.33896827697754\n",
      "The loss after 51 epochs was 19.70602035522461\n",
      "The loss after 61 epochs was 18.885042190551758\n",
      "The loss after 71 epochs was 15.947514533996582\n",
      "The loss after 81 epochs was 18.582767486572266\n",
      "The loss after 91 epochs was 16.953500747680664\n"
     ]
    }
   ],
   "source": [
    "trainer = PyTorchTrainer(pytorch_boston_model, optimizer, criterion)\n",
    "\n",
    "trainer.fit(X_train=X_train, \n",
    "            y_train=y_train, \n",
    "            X_test=X_test, \n",
    "            y_test=y_test,\n",
    "            epochs=100,\n",
    "            eval_every=10,\n",
    "            final_lr_exp = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.172704696655273"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.pow(pytorch_boston_model(X_test, inference=True)[0] - y_test, 2)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = pytorch_boston_model(X_test)[0].view(-1)\n",
    "test_actual = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = test_pred.detach().numpy()\n",
    "test_actual = test_actual.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fedaee43130>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(test_pred, test_actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
